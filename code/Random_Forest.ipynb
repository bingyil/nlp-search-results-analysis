{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import decomposition, pipeline, metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Metric (Quadratic Weighted Kappa)\n",
    "# The following 3 functions are taken from https://github.com/benhamner/Metrics\n",
    "def confusion_matrix(rater_a, rater_b, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the confusion matrix between rater's ratings\n",
    "    \"\"\"\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(rater_a + rater_b)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(rater_a + rater_b)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    conf_mat = [[0 for i in range(num_ratings)]\n",
    "                for j in range(num_ratings)]\n",
    "    for a, b in zip(rater_a, rater_b):\n",
    "        conf_mat[a - min_rating][b - min_rating] += 1\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def histogram(ratings, min_rating=None, max_rating=None):\n",
    "    \"\"\"\n",
    "    Returns the counts of each type of rating that a rater made\n",
    "    \"\"\"\n",
    "    if min_rating is None:\n",
    "        min_rating = min(ratings)\n",
    "    if max_rating is None:\n",
    "        max_rating = max(ratings)\n",
    "    num_ratings = int(max_rating - min_rating + 1)\n",
    "    hist_ratings = [0 for x in range(num_ratings)]\n",
    "    for r in ratings:\n",
    "        hist_ratings[r - min_rating] += 1\n",
    "    return hist_ratings\n",
    "\n",
    "\n",
    "def quadratic_weighted_kappa(y, y_pred):\n",
    "    \"\"\"\n",
    "    Calculates the quadratic weighted kappa\n",
    "    axquadratic_weighted_kappa calculates the quadratic weighted kappa\n",
    "    value, which is a measure of inter-rater agreement between two raters\n",
    "    that provide discrete numeric ratings.  Potential values range from -1\n",
    "    (representing complete disagreement) to 1 (representing complete\n",
    "    agreement).  A kappa value of 0 is expected if all agreement is due to\n",
    "    chance.\n",
    "    quadratic_weighted_kappa(rater_a, rater_b), where rater_a and rater_b\n",
    "    each correspond to a list of integer ratings.  These lists must have the\n",
    "    same length.\n",
    "    The ratings should be integers, and it is assumed that they contain\n",
    "    the complete range of possible ratings.\n",
    "    quadratic_weighted_kappa(X, min_rating, max_rating), where min_rating\n",
    "    is the minimum possible rating, and max_rating is the maximum possible\n",
    "    rating\n",
    "    \"\"\"\n",
    "    rater_a = y\n",
    "    rater_b = y_pred\n",
    "    min_rating=None\n",
    "    max_rating=None\n",
    "    rater_a = np.array(rater_a, dtype=int)\n",
    "    rater_b = np.array(rater_b, dtype=int)\n",
    "    assert(len(rater_a) == len(rater_b))\n",
    "    if min_rating is None:\n",
    "        min_rating = min(min(rater_a), min(rater_b))\n",
    "    if max_rating is None:\n",
    "        max_rating = max(max(rater_a), max(rater_b))\n",
    "    conf_mat = confusion_matrix(rater_a, rater_b,\n",
    "                                min_rating, max_rating)\n",
    "    num_ratings = len(conf_mat)\n",
    "    num_scored_items = float(len(rater_a))\n",
    "\n",
    "    hist_rater_a = histogram(rater_a, min_rating, max_rating)\n",
    "    hist_rater_b = histogram(rater_b, min_rating, max_rating)\n",
    "\n",
    "    numerator = 0.0\n",
    "    denominator = 0.0\n",
    "\n",
    "    for i in range(num_ratings):\n",
    "        for j in range(num_ratings):\n",
    "            expected_count = (hist_rater_a[i] * hist_rater_b[j]\n",
    "                              / num_scored_items)\n",
    "            d = pow(i - j, 2.0) / pow(num_ratings - 1, 2.0)\n",
    "            numerator += d * conf_mat[i][j] / num_scored_items\n",
    "            denominator += d * expected_count / num_scored_items\n",
    "\n",
    "    return (1.0 - numerator / denominator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>query</th>\n",
       "      <th>product_title</th>\n",
       "      <th>product_description</th>\n",
       "      <th>median_relevance</th>\n",
       "      <th>relevance_variance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bridal shower decoration</td>\n",
       "      <td>accent pillow heart design red black</td>\n",
       "      <td>red satin accent pillow embroider heart black ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>lead christmas light</td>\n",
       "      <td>set battery operate multi lead train christmas...</td>\n",
       "      <td>set battery operate train christmas light item...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>projector</td>\n",
       "      <td>viewsonic pro dlp multimedia projector</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wine rack</td>\n",
       "      <td>concept housewares wr solid wood ceiling wall ...</td>\n",
       "      <td>like silent sturdy tree southern enterprise bi...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>light bulb</td>\n",
       "      <td>wintergreen light christmas lead light bulb pack</td>\n",
       "      <td>wtgr feature nickel base average hour acrylic ...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      query  \\\n",
       "0  bridal shower decoration   \n",
       "1      lead christmas light   \n",
       "2                 projector   \n",
       "3                 wine rack   \n",
       "4                light bulb   \n",
       "\n",
       "                                       product_title  \\\n",
       "0               accent pillow heart design red black   \n",
       "1  set battery operate multi lead train christmas...   \n",
       "2             viewsonic pro dlp multimedia projector   \n",
       "3  concept housewares wr solid wood ceiling wall ...   \n",
       "4   wintergreen light christmas lead light bulb pack   \n",
       "\n",
       "                                 product_description  median_relevance  \\\n",
       "0  red satin accent pillow embroider heart black ...                 1   \n",
       "1  set battery operate train christmas light item...                 4   \n",
       "2                                                                    4   \n",
       "3  like silent sturdy tree southern enterprise bi...                 4   \n",
       "4  wtgr feature nickel base average hour acrylic ...                 2   \n",
       "\n",
       "   relevance_variance  \n",
       "0               0.000  \n",
       "1               0.000  \n",
       "2               0.471  \n",
       "3               0.000  \n",
       "4               0.471  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_clean = pd.read_csv(\"./train_clean.csv\")\n",
    "train_clean = train_clean.fillna(\"\")\n",
    "train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = train_clean[\"query\"] + [\" \"] + train_clean[\"product_title\"]\n",
    "traindata = tmp.values.tolist()\n",
    "y = train_clean[\"median_relevance\"].values\n",
    "\n",
    "test_clean = pd.read_csv(\"./test_clean.csv\")\n",
    "test_clean = test_clean.fillna(\"\")\n",
    "tmp = test_clean[\"query\"] + [\" \"] + test_clean[\"product_title\"]\n",
    "testdata = tmp.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count Vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctv = CountVectorizer(analyzer = \"word\", \\\n",
    "                      tokenizer = None, \\\n",
    "                      preprocessor = None, \\\n",
    "                      stop_words = None, \\\n",
    "                      max_features = None) \n",
    "\n",
    "ctv.fit(traindata)\n",
    "X =  ctv.transform(traindata) \n",
    "X_test = ctv.transform(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVD\n",
    "svd = TruncatedSVD()\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Create the pipeline \n",
    "clf = pipeline.Pipeline([('svd', svd),\n",
    "                         ('rf', rf_model)])\n",
    "\n",
    "# Create a parameter grid to search for best parameters for everything in the pipeline\n",
    "param_grid = {'svd__n_components' : [200, 400],\n",
    "              'rf__n_estimators':[10, 30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] rf__n_estimators=10, svd__n_components=200 ......................\n",
      "[CV] rf__n_estimators=10, svd__n_components=200 ......................\n",
      "[CV] rf__n_estimators=10, svd__n_components=400 ......................\n",
      "[CV] rf__n_estimators=10, svd__n_components=400 ......................\n",
      "[CV] rf__n_estimators=30, svd__n_components=200 ......................\n",
      "[CV] rf__n_estimators=30, svd__n_components=200 ......................\n",
      "[CV] rf__n_estimators=30, svd__n_components=400 ......................\n",
      "[CV] rf__n_estimators=30, svd__n_components=400 ......................\n",
      "[CV]  rf__n_estimators=10, svd__n_components=200, score=0.3422331836436202, total=  10.1s\n",
      "[CV]  rf__n_estimators=10, svd__n_components=200, score=0.35695620799726624, total=  10.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:   10.3s remaining:   30.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rf__n_estimators=30, svd__n_components=200, score=0.33750679196636524, total=  12.7s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:   12.9s remaining:   21.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rf__n_estimators=30, svd__n_components=200, score=0.3529915884752872, total=  13.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   13.4s remaining:   13.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rf__n_estimators=10, svd__n_components=400, score=0.28896136122998306, total=  14.3s\n",
      "[CV]  rf__n_estimators=10, svd__n_components=400, score=0.28092957746478875, total=  14.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed:   14.4s remaining:    8.6s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:   14.5s remaining:    4.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rf__n_estimators=30, svd__n_components=400, score=0.2680577535005765, total=  16.3s\n",
      "[CV]  rf__n_estimators=30, svd__n_components=400, score=0.2652465027871209, total=  16.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   16.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   16.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.3496\n",
      "Best parameters set:\n",
      "\trf__n_estimators: 10\n",
      "\tsvd__n_components: 200\n"
     ]
    }
   ],
   "source": [
    "# Kappa Scorer \n",
    "kappa_scorer = metrics.make_scorer(quadratic_weighted_kappa, greater_is_better = True)\n",
    "\n",
    "# Initialize Grid Search Model\n",
    "model = GridSearchCV(estimator = clf, param_grid=param_grid, scoring=kappa_scorer,\n",
    "                     verbose=10, n_jobs=-1, cv=2)\n",
    "\n",
    "# Fit Grid Search Model\n",
    "model.fit(X, y)\n",
    "print(\"Best score: %0.4f\" % model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "# Get best model\n",
    "best_model = model.best_estimator_\n",
    "\n",
    "# Fit model with best parameters optimized for quadratic_weighted_kappa\n",
    "best_model.fit(X,y)\n",
    "preds = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "test = pd.read_csv(\"./data/test.csv\")\n",
    "idx = test[\"id\"].values\n",
    "submission = pd.DataFrame({\"id\": idx, \"prediction\": preds})\n",
    "submission.to_csv(\"CTV_RF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Private leader board score 0.43416."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfv = TfidfVectorizer(min_df=3,  max_features=None, \n",
    "        strip_accents='unicode', analyzer='word',token_pattern=r'\\w{1,}',\n",
    "        ngram_range=(1, 5), use_idf=1,smooth_idf=1,sublinear_tf=1,\n",
    "        stop_words = 'english')\n",
    "\n",
    "tfv.fit(traindata)\n",
    "X =  tfv.transform(traindata) \n",
    "X_test = tfv.transform(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVD\n",
    "svd = TruncatedSVD()\n",
    "# Random Forest\n",
    "rf_model = RandomForestClassifier()\n",
    "\n",
    "# Create the pipeline \n",
    "clf = pipeline.Pipeline([('svd', svd),\n",
    "                         ('rf', rf_model)])\n",
    "\n",
    "# Create a parameter grid to search for best parameters for everything in the pipeline\n",
    "param_grid = {'svd__n_components' : [200, 400],\n",
    "              'rf__n_estimators':[10, 30]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 4 candidates, totalling 8 fits\n",
      "[CV] rf__n_estimators=10, svd__n_components=200 ......................\n",
      "[CV] rf__n_estimators=10, svd__n_components=200 ......................\n",
      "[CV] rf__n_estimators=10, svd__n_components=400 ......................\n",
      "[CV] rf__n_estimators=10, svd__n_components=400 ......................\n",
      "[CV] rf__n_estimators=30, svd__n_components=200 ......................\n",
      "[CV] rf__n_estimators=30, svd__n_components=200 ......................\n",
      "[CV] rf__n_estimators=30, svd__n_components=400 ......................\n",
      "[CV] rf__n_estimators=30, svd__n_components=400 ......................\n",
      "[CV]  rf__n_estimators=10, svd__n_components=200, score=0.394493188112357, total=  12.9s\n",
      "[CV]  rf__n_estimators=10, svd__n_components=200, score=0.3965538285154473, total=  13.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   2 out of   8 | elapsed:   13.2s remaining:   39.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rf__n_estimators=30, svd__n_components=200, score=0.37280817378435327, total=  15.8s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   3 out of   8 | elapsed:   16.0s remaining:   26.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rf__n_estimators=30, svd__n_components=200, score=0.3743110464201195, total=  16.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   4 out of   8 | elapsed:   16.2s remaining:   16.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rf__n_estimators=10, svd__n_components=400, score=0.3447000113822366, total=  18.4s\n",
      "[CV]  rf__n_estimators=10, svd__n_components=400, score=0.36326079267528255, total=  18.4s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   5 out of   8 | elapsed:   18.6s remaining:   11.1s\n",
      "[Parallel(n_jobs=-1)]: Done   6 out of   8 | elapsed:   18.6s remaining:    6.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  rf__n_estimators=30, svd__n_components=400, score=0.3192030323729018, total=  20.6s\n",
      "[CV]  rf__n_estimators=30, svd__n_components=400, score=0.34078530726515943, total=  20.9s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   21.2s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   8 out of   8 | elapsed:   21.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best score: 0.3955\n",
      "Best parameters set:\n",
      "\trf__n_estimators: 10\n",
      "\tsvd__n_components: 200\n"
     ]
    }
   ],
   "source": [
    "# Kappa Scorer \n",
    "kappa_scorer = metrics.make_scorer(quadratic_weighted_kappa, greater_is_better = True)\n",
    "\n",
    "# Initialize Grid Search Model\n",
    "model = GridSearchCV(estimator = clf, param_grid=param_grid, scoring=kappa_scorer,\n",
    "                     verbose=10, n_jobs=-1, cv=2)\n",
    "\n",
    "# Fit Grid Search Model\n",
    "model.fit(X, y)\n",
    "print(\"Best score: %0.4f\" % model.best_score_)\n",
    "print(\"Best parameters set:\")\n",
    "best_parameters = model.best_estimator_.get_params()\n",
    "for param_name in sorted(param_grid.keys()):\n",
    "    print(\"\\t%s: %r\" % (param_name, best_parameters[param_name]))\n",
    "\n",
    "# Get best model\n",
    "best_model = model.best_estimator_\n",
    "\n",
    "# Fit model with best parameters optimized for quadratic_weighted_kappa\n",
    "best_model.fit(X,y)\n",
    "preds = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create submission file\n",
    "submission = pd.DataFrame({\"id\": idx, \"prediction\": preds})\n",
    "submission.to_csv(\"TFIDF_RF.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Private leader board score 0.45534."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
